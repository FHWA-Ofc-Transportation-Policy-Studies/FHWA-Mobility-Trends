{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486d4f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import time\n",
    "import requests\n",
    "import urllib\n",
    "import zipfile\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "#from platforms.connect.snowpy import SnowPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98ff61",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6c7f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrowe\\Documents\\FHWA mobility trend report\\T4 - Forecasting\\Year 2\\modeling code\\etl\\NES\\NES_CPB_NES_Combined\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "datapath = os.getcwd() + '/nes_zips/'\n",
    "#datapath = 'vol-1/NES_CPB_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f313295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def try_download(url, file):\n",
    "    #makedir_if_needed(datapath)\n",
    "    try:\n",
    "        download_url(url, file)\n",
    "        print(f\"Downloaded {url} to {file}\")\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f\"Couldn't find {url}, Exception: {e}\")\n",
    "        \n",
    "def uncompress(filepath):\n",
    "    # Uncompress if zip file\n",
    "    if filepath[-4:].lower() == '.zip':\n",
    "        zipfolder = filepath.split('/')[-1].split('.')[0]\n",
    "        print(f'                Uncompressing zip file to folder {zipfolder}')\n",
    "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(datapath + zipfolder)\n",
    "            \n",
    "            \n",
    "#example url https://www2.census.gov/programs-surveys/nonemployer-statistics/datasets/2019/historical-datasets/combine19_txt.zip\n",
    "#            https://www2.census.gov/programs-surveys/nonemployer-statistics/datasets/2016/combine16_txt.zip\n",
    "#            https://www2.census.gov/programs-surveys/nonemployer-statistics/datasets/2012/historical-datasets/combine12_txt.zip\n",
    "#            https://www2.census.gov/programs-surveys/nonemployer-statistics/datasets/2020/historical-datasets/nonemp20co.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1efd4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nes_county_files():\n",
    "    for year in range(2000,2021):\n",
    "        print(year)\n",
    "        url = 'https://www2.census.gov/programs-surveys/nonemployer-statistics/datasets/' + str(year) + '/historical-datasets/nonemp' + str(year)[2:] + 'co.zip'\n",
    "        file_name = 'NES_County_' + str(year) + '.zip'\n",
    "        download_url(url, datapath + file_name)\n",
    "        uncompress(datapath + file_name)\n",
    "        os.remove(datapath + file_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4a8c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nonemp00co.zip: 0.00B [00:00, ?B/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\hrowe\\\\Documents\\\\FHWA mobility trend report\\\\T4 - Forecasting\\\\Year 2\\\\modeling code\\\\etl\\\\NES\\\\NES_CPB_NES_Combined/nes_zips/NES_County_2000.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10600\\371057454.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdownload_nes_county_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10600\\1330414672.py\u001b[0m in \u001b[0;36mdownload_nes_county_files\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www2.census.gov/programs-surveys/nonemployer-statistics/datasets/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/historical-datasets/nonemp'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'co.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'NES_County_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0muncompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10600\\2283666177.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, output_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m     with DownloadProgressBar(unit='B', unit_scale=True,\n\u001b[0;32m      9\u001b[0m                              miniters=1, desc=url.split('/')[-1]) as t:\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtry_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;31m# Handle temporary file setup.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[0mtfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0mtfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\hrowe\\\\Documents\\\\FHWA mobility trend report\\\\T4 - Forecasting\\\\Year 2\\\\modeling code\\\\etl\\\\NES\\\\NES_CPB_NES_Combined/nes_zips/NES_County_2000.zip'"
     ]
    }
   ],
   "source": [
    "download_nes_county_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8edfa2",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#vol-1/NES_CPB_files/NES_CPB2014/combine14.txt\n",
    "\n",
    "#datapath = 'vol-1/NES_CPB_files/'\n",
    "\n",
    "for year in range(2012,2020):\n",
    "    print(year)\n",
    "    df = pd.read_csv(datapath + 'NES_CPB' + str(year) + '/combine' + str(year)[2:] + '.txt', \n",
    "                    dtype = str)\n",
    "    df_columns = df.columns\n",
    "    df.columns = ['STATE', 'SDSCR', 'COUNTY', 'CTYDSCR', 'NAICS', 'NCSDSCR', 'CESTAB', 'CBP_PCT',\n",
    "                 'NES_PCT', 'EST', 'EMP', 'EMP_NF', 'QP1', 'QP1_NF', 'AP', 'AP_NF', 'ESTAB', 'RCPTOT', 'RCPTOT_N_F']\n",
    "    df = df[['STATE', 'SDSCR', 'COUNTY', 'CTYDSCR', 'NAICS', 'NCSDSCR', 'CESTAB', 'CBP_PCT', \n",
    "             'NES_PCT', 'EST', 'EMP', 'EMP_NF', 'QP1', 'QP1_NF', 'AP', 'AP_NF', 'ESTAB', 'RCPTOT', 'RCPTOT_N_F']]\n",
    "    df.to_csv(datapath + 'NES_CPB' + str(year) + '/transformed_nonemp' + str(year)[2:] + 'co.csv', index = False)\n",
    "    print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f7423",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import time\n",
    "import requests\n",
    "import urllib\n",
    "import zipfile\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from platforms.connect.snowpy import SnowPy\n",
    "from sqlalchemy.dialects import registry\n",
    "registry.register('snowflake', 'snowflake.sqlalchemy', 'dialect')\n",
    "\n",
    "\n",
    "datapath = 'vol-1/NES_CPB_files/'\n",
    "\n",
    "snowpy = SnowPy()\n",
    "\n",
    "# login (return to add .env variabels)\n",
    "account = os.environ['Account']\n",
    "role = os.environ['Role']\n",
    "ctx = snowpy.login(account, role, reauthenticate = True)\n",
    "\n",
    "# Establish SnowFlake connection\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'FHWA_DEV'  # For production use FHWA_DB\n",
    "schema = 'RAW'  # Source data stored in Schema RAW, transformed (curated) data stored in CUR\n",
    "\n",
    "ctx.execute(f'USE WAREHOUSE {warehouse}')\n",
    "ctx.execute(f'USE DATABASE {database}')\n",
    "ctx.execute(f'USE SCHEMA {schema}') \n",
    "\n",
    "table_name = 'NES_CPB_COMBINED'\n",
    "\n",
    "for year in range(2012,2020):\n",
    "    print(year)\n",
    "    df = pd.read_csv(datapath + 'NES_CPB' + str(year) + '/transformed_nonemp' + str(year)[2:] + 'co.csv',\n",
    "                    dtype = str) \n",
    "    df['YEAR'] = year\n",
    "    print(df.head)\n",
    "    if year == 2012:\n",
    "        snowpy.create_new_table(df = df, warehouse = warehouse, database = database, \n",
    "                            schema = schema, table = table_name, large_transfer= True, chunksize = 100000)  \n",
    "    else:\n",
    "        snowpy.modify_rows(df=df, warehouse=warehouse, database=database, operation = 'append', schema=schema, table=table_name, log=True, keep_alive=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
