library(car)
library(caret)
library(tidyr)
library(glmnet) #documentation at: https://glmnet.stanford.edu/articles/glmnet.html
library(corrplot)
library(ggplot2)
library(tidyverse)
#################################### Inputs to edit #################################
#clear workspace
rm(list = setdiff(ls(), lsf.str()))
#load in the data you want to use
df <- read.csv("C:/Users/zapate/Desktop/FHWA_Mobility_Trends/Year 2 County Level/Modeling_Year1_County_level/Data/County_Year2_1_10_24.csv")
##### Final GHG Model (run on 1/8/23)
#set the list of indicators you want to work with
indicators <- c("POPULATION","True_GDP","Unemployment_Rate", "Charging_Stations","LNMILES","TELEWORK","UPT_distr_commuters", "COURIER_NONEMP_RCPTOT_REAL", "DRIVER_NONEMP_RCPTOT_REAL", "POP_DENSITY")
non_indicator_var <- c("Full_FIPS_Code", "YEAR", "County_Type")
y <-  "TOTAL_EMISSIONS" #set your dependent variable
train_percent <- 0.7 #set the percent of data you want to use in the train set
n = 1 #define number of model trials you want to run
remove_y_zeros <- TRUE #(set to FLASE if preferred to keep zeros in)
#run this at the end if you want to save this model coefficents
#saveRDS(best_model, "C:/Users/hrowe/Documents/FHWA mobility trend report/T4 - Forecasting/Year 2/FHWA_Mobility_Trends/Year 2 County Level/Modeling_Year1_County_level/Modeling/champion_TMS_y2_1_10_24.rds")
best_model <- readRDS("C:/Users/zapate/Desktop/FHWA_Mobility_Trends/Year 2 County Level/Modeling_Year1_County_level/Modeling/champion_GHG_y2_1_8_24.rds")
round(coef(best_model), digits = 4)
#setting seed value
set.seed(102)
#grab data and drop all NA
df <- drop_na(df[,c(indicators, y, non_indicator_var)])
#remove cases where y is zero, depending on parameter given in the inputs section
if(remove_y_zeros){
df <- df %>%
filter(!!sym(y) != 0) #replace TOTAL_EMISSIONS with y if we want this to work for all performance measures
}
# make copy of year and for later
df_year <- subset(df, select=c(YEAR))
df_county_type <- subset(df, select=c(County_Type))
#one_hot encode data
df$Full_FIPS_Code <- as.factor(df$Full_FIPS_Code)
unique_FIPS <- unique(df$Full_FIPS_Code)
dum <- dummyVars(" ~ Full_FIPS_Code", data = df)
counties_onehot <- data.frame(predict(dum, newdata = df))
df <- cbind(df, counties_onehot)
#log convert all data (even rates, as it helps with skew and uniformity of data)
all_var <- c(y, indicators)
log_var <- paste("LOG", all_var, sep ="")
log_y <- log_var[1]
for (a in all_var){
temp <- log(df[[a]] + 1)
title <- paste("LOG", a, sep ="")
df[title] <- temp
}
#removing non log transformed indicators and performance measure
df <- df[ , -which(names(df) %in% c(indicators, y))]
# Min-max scaling the data
process <- preProcess(as.data.frame(df), method=c("range"))
norm_scale <- predict(process, as.data.frame(df))
norm_scale_colnames <- colnames(norm_scale)
#adding back year, county type, and pre-min max scaled performance measure
norm_scale[["YEAR"]] <- as.numeric(df[["YEAR"]])
norm_scale[["County_Type"]] <- df[["County_Type"]]
norm_scale[[log_y]] <- df[[log_y]]
#initializing df to hold results from n trials
var_and_eval <- c(log_var[-1], "r2_test", "rmse_norm_test")
df_n_trials <- data.frame(matrix(ncol = length(var_and_eval), nrow = 0))
colnames(df_n_trials) <- var_and_eval
#train test split
smp_size <- floor(train_percent * nrow(norm_scale))
train_ind <- sample(seq_len(nrow(norm_scale)), size = smp_size)
train <- norm_scale[train_ind, ]
test <- norm_scale[-train_ind, ]
#test predictions
#remove - lasso_pred_test <- predict(best_model,  as.matrix(subset(test, select = -c(LOGTOTAL_EMISSIONS, Full_FIPS_Code, YEAR, County_Type))))
lasso_pred_test <- predict(best_model,  as.matrix(select(test, -one_of(c(log_y, non_indicator_var)))))
test$preds = lasso_pred_test
test$resids =test[[log_y]] - test$preds
#test analysis
test_rmse <- sqrt(mean(test$resids ^ 2))
test_rmse_norm <- test_rmse / (max(test[[log_y]]) - min(test[[log_y]]) )
test_mae <- mean(abs(test$resids))
test_mae_norm <- test_mae / (max(test[[log_y]]) - min(test[[log_y]]) )
test_mse <- mean(test$resids ^ 2)
test_r2 <- cor(test[[log_y]], lasso_pred_test)^2
#train predictions
#remove - lasso_pred_train <- predict(best_model,  as.matrix(subset(train, select = -c(LOGTOTAL_EMISSIONS, Full_FIPS_Code, YEAR, County_Type))))
lasso_pred_train <- predict(best_model,  as.matrix(select(train, -one_of(c(log_y, non_indicator_var)))))
train$preds = lasso_pred_train
train$resids = train[[log_y]] - train$preds
#train analysis
train_rmse <- sqrt(mean(train$resids ^ 2))
train_rmse_norm <- train_rmse / (max(train[[log_y]]) - min(train[[log_y]]) )
train_mae <- mean(abs(train$resids))
train_mae_norm <- train_mae / (max(train[[log_y]]) - min(train[[log_y]]) )
train_mse <- mean(train$resids ^ 2)
train_r2 <- cor(train[[log_y]], lasso_pred_train)^2
#evaluation metrics
metrics_df <- data.frame(performance_measure = c("RMSE","RMSE Normalized", "MAE","MAE Normalized", "MSE", "R2"),
test = round(c(test_rmse, test_rmse_norm, test_mae, test_mae_norm, test_mse, test_r2  ), digits = 4),
train = round(c(train_rmse, train_rmse_norm, train_mae, train_mae_norm, train_mse, train_r2  ), digits = 4))
metrics_df
all_preds <- predict(best_model, as.matrix(select(norm_scale, -one_of(c(log_y, non_indicator_var)))))
norm_scale$Log_predictions <- all_preds
norm_scale$Predictions <- exp(norm_scale$Log_predictions)
write.csv(subset(norm_scale, select = c(Full_FIPS_Code, YEAR, County_Type, Log_predictions, Predictions,
LOGTOTAL_EMISSIONS,LOGPOPULATION,LOGTrue_GDP,LOGUnemployment_Rate,LOGCharging_Stations,
LOGLNMILES, LOGTELEWORK, LOGUPT_distr_commuters, LOGCOURIER_NONEMP_RCPTOT_REAL, LOGDRIVER_NONEMP_RCPTOT_REAL,
LOGPOP_DENSITY)), 'TOTAL_EMISSIONS Modeling Dataset and results.csv')
#transforing forecast data for prediction
#baseline
forecast_data1 = read.csv("C:/Users/zapate/Desktop/FHWA_Mobility_Trends/Year 2 County Level/forecasting/Model Data/Forecast_Data 1_16_2023.csv")
forecast_data = forecast_data1[,c("Pop.Linear",
"Real.GDP",
"Unemployment.MA",
"EV.1",
"Lane.Miles.1",
"Telework.1",
"Transit",
"Driver.Rev.Baseline",
"Courier.Baseline",
"POPDENSITY",
"YEAR",
"FIPS")]
colnames(forecast_data) <- c("POPULATION","True_GDP","Unemployment_Rate", "Charging_Stations","LNMILES"
,"TELEWORK","UPT_distr_commuters","DRIVER_NONEMP_RCPTOT_REAL","COURIER_NONEMP_RCPTOT_REAL","POP_DENSITY", "YEAR", "Full_FIPS_Code")
forecast_data[is.na(forecast_data)] <- 0
####
forecast_data <- drop_na(forecast_data[,c("POPULATION","True_GDP","Unemployment_Rate", "Charging_Stations","LNMILES"
,"TELEWORK","UPT_distr_commuters","DRIVER_NONEMP_RCPTOT_REAL","COURIER_NONEMP_RCPTOT_REAL","POP_DENSITY", "Full_FIPS_Code", "YEAR")]) #removed year and gems geotype
forecast_data$Unemployment_Rate <- forecast_data$Unemployment_Rate / 100
# make copy of year and for later
forecast_data_year <- subset(forecast_data, select=c(YEAR))
#one_hot encode data
forecast_data$Full_FIPS_Code <- as.factor(forecast_data$Full_FIPS_Code)
dum <- dummyVars(" ~ Full_FIPS_Code", data = forecast_data)
counties_onehot <- data.frame(predict(dum, newdata = forecast_data))
forecast_data <- cbind(forecast_data, counties_onehot)
#log convert all data (even rates, as it helps with skew and uniformity of data)
all_var <- c(y, indicators)
log_var <- paste("LOG", all_var, sep ="")
log_y <- log_var[1]
for (a in all_var){
temp <- log(forecast_data[[a]] + 1)
title <- paste("LOG", a, sep ="")
forecast_data[title] <- temp
}
#removing non log transformed indicators and performance measure
forecast_data <- forecast_data[ , -which(names(forecast_data) %in% c(indicators, y))]
# Min-max scaling the data
norm_scale <- predict(process, as.data.frame(forecast_data))
#adding back year, county type, and pre-min max scaled performance measure
norm_scale[["YEAR"]] <- as.numeric(forecast_data[["YEAR"]])
norm_scale$County_Type <- 0
norm_scale <- norm_scale[,norm_scale_colnames]
norm_scale
all_forecast_preds <- predict(best_model, as.matrix(subset(norm_scale, select = -c(County_Type, Full_FIPS_Code, YEAR, LOGTOTAL_EMISSIONS))))
norm_scale$Log_predictions <- all_forecast_preds[,1]
norm_scale$Predictions <- exp(norm_scale$Log_predictions)
norm_scale$YEAR <- forecast_data$YEAR
write.csv(subset(norm_scale, select = c(Full_FIPS_Code, YEAR, County_Type, Log_predictions, Predictions,
LOGTOTAL_EMISSIONS,LOGPOPULATION,LOGTrue_GDP,LOGUnemployment_Rate,LOGCharging_Stations,
LOGLNMILES, LOGTELEWORK, LOGUPT_distr_commuters, LOGCOURIER_NONEMP_RCPTOT_REAL, LOGDRIVER_NONEMP_RCPTOT_REAL,
LOGPOP_DENSITY)), 'TOTAL_EMISSIONS Forecast Dataset and results.csv')
write.csv(subset(norm_scale, select = c(Full_FIPS_Code, YEAR, County_Type, Log_predictions, Predictions,
LOGTOTAL_EMISSIONS,LOGPOPULATION,LOGTrue_GDP,LOGUnemployment_Rate,LOGCharging_Stations,
LOGLNMILES, LOGTELEWORK, LOGUPT_distr_commuters, LOGCOURIER_NONEMP_RCPTOT_REAL, LOGDRIVER_NONEMP_RCPTOT_REAL,
LOGPOP_DENSITY)), 'C:/Users/zapate/Desktop/FHWA_Mobility_Trends/Year 2 County Level/forecasting/TOTAL_EMISSIONS Forecast Dataset and results.csv')
library(car)
library(caret)
library(tidyr)
library(glmnet) #documentation at: https://glmnet.stanford.edu/articles/glmnet.html
library(corrplot)
library(ggplot2)
library(tidyverse)
#################################### Inputs to edit #################################
#clear workspace
rm(list = setdiff(ls(), lsf.str()))
#load in the data you want to use
df <- read.csv("C:/Users/zapate/Desktop/FHWA_Mobility_Trends/Year 2 County Level/Modeling_Year1_County_level/Data/County_Year2_1_10_24.csv")
##### Final GHG Model (run on 1/8/23)
#set the list of indicators you want to work with
indicators <- c("POPULATION","True_GDP","Unemployment_Rate", "Charging_Stations","LNMILES","TELEWORK","UPT_distr_commuters", "COURIER_NONEMP_RCPTOT_REAL", "DRIVER_NONEMP_RCPTOT_REAL", "POP_DENSITY")
non_indicator_var <- c("Full_FIPS_Code", "YEAR", "County_Type")
y <-  "TOTAL_EMISSIONS" #set your dependent variable
train_percent <- 0.7 #set the percent of data you want to use in the train set
n = 1 #define number of model trials you want to run
remove_y_zeros <- TRUE #(set to FLASE if preferred to keep zeros in)
#run this at the end if you want to save this model coefficents
#saveRDS(best_model, "C:/Users/hrowe/Documents/FHWA mobility trend report/T4 - Forecasting/Year 2/FHWA_Mobility_Trends/Year 2 County Level/Modeling_Year1_County_level/Modeling/champion_TMS_y2_1_10_24.rds")
best_model <- readRDS("C:/Users/zapate/Desktop/FHWA_Mobility_Trends/Year 2 County Level/Modeling_Year1_County_level/Modeling/champion_GHG_y2_1_8_24.rds")
round(coef(best_model), digits = 4)
#################################### Structure #################################
#setting seed value
set.seed(102)
#grab data and drop all NA
df <- drop_na(df[,c(indicators, y, non_indicator_var)])
#remove cases where y is zero, depending on parameter given in the inputs section
if(remove_y_zeros){
df <- df %>%
filter(!!sym(y) != 0) #replace TOTAL_EMISSIONS with y if we want this to work for all performance measures
}
# make copy of year and for later
df_year <- subset(df, select=c(YEAR))
df_county_type <- subset(df, select=c(County_Type))
#one_hot encode data
df$Full_FIPS_Code <- as.factor(df$Full_FIPS_Code)
unique_FIPS <- unique(df$Full_FIPS_Code)
dum <- dummyVars(" ~ Full_FIPS_Code", data = df)
counties_onehot <- data.frame(predict(dum, newdata = df))
df <- cbind(df, counties_onehot)
#log convert all data (even rates, as it helps with skew and uniformity of data)
all_var <- c(y, indicators)
log_var <- paste("LOG", all_var, sep ="")
log_y <- log_var[1]
for (a in all_var){
temp <- log(df[[a]] + 1)
title <- paste("LOG", a, sep ="")
df[title] <- temp
}
#removing non log transformed indicators and performance measure
df <- df[ , -which(names(df) %in% c(indicators, y))]
# Min-max scaling the data
process <- preProcess(as.data.frame(df), method=c("range"))
norm_scale <- predict(process, as.data.frame(df))
norm_scale_colnames <- colnames(norm_scale)
#adding back year, county type, and pre-min max scaled performance measure
norm_scale[["YEAR"]] <- as.numeric(df[["YEAR"]])
norm_scale[["County_Type"]] <- df[["County_Type"]]
norm_scale[[log_y]] <- df[[log_y]]
#initializing df to hold results from n trials
var_and_eval <- c(log_var[-1], "r2_test", "rmse_norm_test")
df_n_trials <- data.frame(matrix(ncol = length(var_and_eval), nrow = 0))
colnames(df_n_trials) <- var_and_eval
#train test split
smp_size <- floor(train_percent * nrow(norm_scale))
train_ind <- sample(seq_len(nrow(norm_scale)), size = smp_size)
train <- norm_scale[train_ind, ]
test <- norm_scale[-train_ind, ]
#test predictions
#remove - lasso_pred_test <- predict(best_model,  as.matrix(subset(test, select = -c(LOGTOTAL_EMISSIONS, Full_FIPS_Code, YEAR, County_Type))))
lasso_pred_test <- predict(best_model,  as.matrix(select(test, -one_of(c(log_y, non_indicator_var)))))
test$preds = lasso_pred_test
test$resids =test[[log_y]] - test$preds
#test analysis
test_rmse <- sqrt(mean(test$resids ^ 2))
test_rmse_norm <- test_rmse / (max(test[[log_y]]) - min(test[[log_y]]) )
test_mae <- mean(abs(test$resids))
test_mae_norm <- test_mae / (max(test[[log_y]]) - min(test[[log_y]]) )
test_mse <- mean(test$resids ^ 2)
test_r2 <- cor(test[[log_y]], lasso_pred_test)^2
#train predictions
#remove - lasso_pred_train <- predict(best_model,  as.matrix(subset(train, select = -c(LOGTOTAL_EMISSIONS, Full_FIPS_Code, YEAR, County_Type))))
lasso_pred_train <- predict(best_model,  as.matrix(select(train, -one_of(c(log_y, non_indicator_var)))))
train$preds = lasso_pred_train
train$resids = train[[log_y]] - train$preds
#train analysis
train_rmse <- sqrt(mean(train$resids ^ 2))
train_rmse_norm <- train_rmse / (max(train[[log_y]]) - min(train[[log_y]]) )
train_mae <- mean(abs(train$resids))
train_mae_norm <- train_mae / (max(train[[log_y]]) - min(train[[log_y]]) )
train_mse <- mean(train$resids ^ 2)
train_r2 <- cor(train[[log_y]], lasso_pred_train)^2
#evaluation metrics
metrics_df <- data.frame(performance_measure = c("RMSE","RMSE Normalized", "MAE","MAE Normalized", "MSE", "R2"),
test = round(c(test_rmse, test_rmse_norm, test_mae, test_mae_norm, test_mse, test_r2  ), digits = 4),
train = round(c(train_rmse, train_rmse_norm, train_mae, train_mae_norm, train_mse, train_r2  ), digits = 4))
metrics_df
all_preds <- predict(best_model, as.matrix(select(norm_scale, -one_of(c(log_y, non_indicator_var)))))
norm_scale$Log_predictions <- all_preds
norm_scale$Predictions <- exp(norm_scale$Log_predictions)
write.csv(subset(norm_scale, select = c(Full_FIPS_Code, YEAR, County_Type, Log_predictions, Predictions,
LOGTOTAL_EMISSIONS,LOGPOPULATION,LOGTrue_GDP,LOGUnemployment_Rate,LOGCharging_Stations,
LOGLNMILES, LOGTELEWORK, LOGUPT_distr_commuters, LOGCOURIER_NONEMP_RCPTOT_REAL, LOGDRIVER_NONEMP_RCPTOT_REAL,
LOGPOP_DENSITY)), 'C:/Users/zapate/Desktop/FHWA_Mobility_Trends/Year 2 County Level/forecasting/TOTAL_EMISSIONS Modeling Dataset and results.csv')
